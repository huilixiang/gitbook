##将要学习的内容
- 在每次只学习一层的情况下，怎么从无label数据中学习多层生成模型   

    怎样在每个隐层中添加markov随机场  
- 怎样使用生成模型进行判断训练，使得效果比分类和回归要好  

    Gaussian Processes
- 怎样在大数据集上进行非线性降维
    
- 怎样在高维序列数据上学习多层生成模型

## 机器学习任务系列

| 经典统计学       |  AI            |
|-----------------|-------------------|
| 低维 维度 < 100  | 高维 |
| 数据中有大量的噪声| 噪声不足以影响数据的内在结构（当我们使用恰当的处理方法时）|
| 数据的内在结构不复杂，用一个相对简单的模型就可以表示它| 数据有复杂的结构，不可能用一个简单的模型来表示它 |
| 主要任务是区分噪声 | 主要是任务是找到一个可学习的、能够表征数据复杂结构的方式|

## 时代背景
### 第一代nn ( ~1960)
perceptrons ,感知机， 1960年以前。 使用一个手工编码特征的层，通过学习这些特征的权重来达到识别物体
- 有一个整洁的学习方法来调整权重
- 这种学习方法从根本上限制了感知机

### 第二代nn (~1980)
#### BP算法问世
#### 小插曲
vapnik和他的同事们发明了一个聪明的感知机：SVM
- 不再使用手工编码、没有适应能力特征的层。每个训练样本会通过一定的方法生成新的特征
- 灵巧的优化方法来选择最优特征集。当在对测试样本进行分类时调整特征的权重。 本质上还是感知机。有同样的局限性
1990s,很多研究学者抛弃了多隐层的nn, 转投svm的怀抱： svm更优秀

#### BP问题在哪里
- 需要标签数据
- 训练时间太慢
- 会陷入局部最优

#### 克服BP的局限
- 保留通过梯度来调整特征权重的方法， 但拿它来对sensory input建模   

    调整生成模型的权重，使得当前sensory input的概率最大
    学习P(image) not P(label|image)
- 选择哪种类型的生成模型呢？
#### Belief Nets
- 由随机变量构成的有向无环图  
- 开始关注其中的一些变量， 可以解决两个问题： 
   - 推断问题。 推断没有关注的变量的状态
   - 学习问题。 调整变量之间的交互关系， 使得网络更倾向生成观测变量
   
- 我们使用stochastic binary variables构建的层 和 层之间加权的连接来构建网络。稍后我们会推广到其它类型的变量

#### stochastic binary units (伯努利变量)
- 只有0 / 1 状态
- 该单元被激活的概率由其它输入单元的权重决定（可以有bias）

#### 学习dbn


















