### 背景
包调的多了，困惑也更多了。
1. 机器学习是如何与统计学基在一起的？
2. 简单如斯的LR模型为何横行天下？
3. 为什么要有训练集和测试集？ 理论依赖是什么？

### 机器学习的公式化定义
#### 问题定义
- 观测样本：$$ S = \{(x_1,y_1),...,(x_i, y_i)\} $$ 
- 学习： 给定$$x_i$$ 推断 $$y_i$$    即: $$P(Y|X)$$

#### 目标函数的由来
- 联合分布 $$P(X,Y) = P(Y|X)p(X)$$, 需要知道两个分布，很难
- 直接对P(Y|X)建模--其实也挺难。 我们换个思路对：  

      两个随机变量V,W
      V = E[V|W] + (V - E[V|W])
      令Z = V - E[V|W]. 
      根据全期望公式： E[Z] = E[V] - E[E[V|W]] = E[V] - E[V] = 0!!!
      Z 与 W 无关
- 对于任意的$$(v_i, w_i)$$, 两者的关系可以描述为： 
   
  $$v_i = E[V|W=w_i] + \zeta $$ 
  其中 $$\zeta \subseteq Z$$ ，噪声项
- 我们可以把上述的关系描述应用到我们的统计模型上： 

  $$y_i = E[Y|X=x_i] + \zeta $$ . 存在一些函数： $$f(x) = E[Y|X=x] $$
 
- P(Y|X) 可以表示成如下方式：    
  $$y = f(x) + \zeta$$







