# 线性模型
## 大纲
- [线性模型](#linear_model)
- [回归与分类](#rgr_cls)
- [最小二乘与极大似然](#ols_mle)
- [正则化与先验](#rgl_pri)
- [逻辑回归的损失函数](#lr_loss)
- [广义线性模型](#glm)
- [广义可加模型](#gam)

## 线性模型<span id="linear_model"></span>
响应变量(因变量)y是关于预测变量（自变量）x的线性函数
### 简单线性模型
只有一个预测变量
$$ y_i = w_0 + w_1X_i + \epsilon_i $$
### 多元线性模型
具有多个预测变量
$$ Y_i = w_0 + w_1X_{1i}+w_2X_{2i}+...+w_nX_{ni} + \epsilon_i  $$   
### 回归与分类<span id="rgr_cls"></span>
Y是定量变量-->回归， 常用线性回归
Y是定性变量-->分类， 常用逻辑回归
### 多元线性回归
- 预测变量是定量变量
- 误差项独立且服从$$N(0, σ^2)$$
- 预测变量X与响应变量Y的真实关系F是未知， 用一个线性函数G去近似F
- 衡量G与F的近似程度    
  RSS: $$ \sum_{1}^{n} \{Y - G(x)\}^{2} $$
- 求解过程， 找到合适的G，使得RSS最小, 最小二乘
### 分类问题
- 对于二分类问题可以直接用线性回归？
- 如果要预测属于某个类别的概率呢？
- 多分类怎么办？
### 逻辑回归
- logit函数  
 ####  $$ ln(\frac{p}{1-p}) = w_0 + w^TX $$
- logit反函数 logistic function:
 ###  $$ p(X) = \frac{e^{w_0 + w^TX }}{1+e^{w_0 + w^TX} }$$
- 极大似然  
  给定X,W时，$$ Y \subseteq{\{0,1\}} $$  
      
  $$ p(Y|X,W) \sim Bernoulli(\varphi) $$
  
  假设所有的Y独立同分布， 则联合概率密度：
  #### L(w) = $$\prod_{i}^{n} p(x)^y \cdot (1-p(x))^{1 - y}$$
  #### max L(w)
  
### 线性回归
  
  
