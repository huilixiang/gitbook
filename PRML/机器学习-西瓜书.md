## 机器学习西瓜书
### 定律 定义 公理 定理
- 纯理论逻辑中才有定理、定义、公理
- 实验物理中有理论又有实验， 所以才有定律、定义、公理
- 公理： 是依据人类理性的不证自明的基本事实， 经过人类的长期反复实践的考验， 不再需加证明的基本命题。 在数学中， 公理是指用来推导其它命题的起点。
- 定理 是经过受逻辑限制的证明为真的陈述， 在数学中，只有重要或有趣的陈述才叫定理。证明定理是数学的中心活动。
- 引理 是为证明某个定理或解某个问题所要用到的命题。引理和定理没有严格的区分，如果论证某个命题时，还没有直接根据，需要某些还没有被证明的结论，把它提出来加以证明，就是所谓的构造引理
- 定律 是客观规律的统称，是解锁宇宙奥秘的钥匙。定律是了解宇宙的基石。是从亘古到现代不曾改变的宇宙规律

### 归纳与演绎
归纳与演绎是科学推理的两个基本手段
- 归纳 induction, 从特殊到一般的泛化过程， 即从特殊事件给出一般性规律
- 演绎 deduction, 从一般到特殊的过程， 即从基本原理推演出具体状态。如从数学公理推导出与之相洽的定理。
- 机器学习是从样例中学习， 属于归纳学习。 induction learning.
- 归纳偏好 通过学习得到的模型对应了假设空间中的一个假设。 任何一个机器学习算法必有其归纳偏好， 否则它将被假设空间中看似训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。
- 奥卡姆剃刀原因： 若有多个假设与观察一致，则选择最简单的那一个。

### No free luanch
- 假设样本空间 $$\chi$$, 假设空间H , $$P(h|x,L_a)$$代表算法$$L_a$$基于训练数据X产生假设h的概率。 再令f代表我们希望学习的真实目标函数。 $$L_a$$的训练集外误差, 即在所有训练集样本之外的误差：
$$E_{ote}(L_a|X,f) = \sum_h \sum_{x\in \chi - X} P(x)I(h(x)!=f(x))P(h|X,L_a) $$ , 其中I是指示函数。
- 考虑二分类问题， 真实目标函数可以是任意的函数：$$\chi \rightarrow \{0,1\}, 函数空间为\{0,1\}^{|\chi|}$$, 对所有可能的f按均匀分布对误差求和：

$$\sum_fE_{ote}(L_a|X,f) = \sum_f\sum_h \sum_{x\in \chi - X} P(x)I(h(x)!=f(x))P(h|X,L_a) $$
$$=\sum_h \sum_{x\in \chi - X} P(x)P(h|X,L_a)\sum_fI(h(x)!=f(x)) $$
$$=2^{|\chi|-1} \cdot \sum_{x\in \chi - X} P(x) \sum_hP(h|X,L_a) $$
$$=2^{|\chi|-1} \cdot \sum_{x\in \chi - X} P(x) \cdot 1$$
- 训练集外误差与算法无关！！！ no free launch
- 但 NFL 定理有一个重要前提： 所有问题出现的机会相同、或所有问题同等重要。但实际并非如此。 但它的寓意在于： 脱离具体问题，空谈“什么学习算法好”毫无意义。

### 机器学习的发展历程
- 推理期， 证明数学原理
- 知识期， 人总结知识告诉机器
- 学习期， 机械学习，示教学习，类比学习，归纳学习。
- 统计学习。
- 深度学习。

##

