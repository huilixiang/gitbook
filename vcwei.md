##VC 维
### 问题
- LR这类简单的模型为什么应用广泛（暗含效果不错）
- bias---variance tradeoff 背后的原理或依据是什么？
### 什么是学习问题
- 术语： 大写的X/Y分别代表服从$$P_x/P_y$$分布的随机变量， 小写的x/y代表随机变量可取的具体值
- 观测样本：$$ S = \{(x_1,y_1),...,(x_i, y_i)\} $$ 
- 学习： 给定$$x_i$$ 推断 $$y_i$$    即: $$P(Y|X)$$
### 目标函数
- 联合分布 $$P(X,Y) = P(Y|X)p(X)$$, 需要知道两个分布，很难
- 直接对P(Y|X)建模--其实也挺难。 我们换个思路对：  

      两个随机变量V,W
      V = E[V|W] + (V - E[V|W])
      令Z = V - E[V|W]. 
      根据全期望公式： E[Z] = E[V] - E[E[V|W]] = E[V] - E[V] = 0!!!
      Z 与 W 无关
- 对于任意的$$(v_i, w_i)$$, 两者的关系可以描述为： 
   
  $$v_i = E[V|W=w_i] + \zeta $$ 
  其中 $$\zeta \subseteq Z$$ ，噪声项
- 我们可以把上述的关系描述应用到我们的统计模型上： 

  $$y_i = E[Y|X=x_i] + \zeta $$ . 存在一些函数： $$f(x) = E[Y|X=x] $$
 
- P(Y|X) 可以表示成如下方式：    
  $$y = f(x) + \zeta$$
  
### 假设
- 目标函数有无穷多个， 不可能穷举每个函数来找到最优的目标函数
- 一般假设目标函数f是线性、多项式甚至更复杂的非线性关系，如神经网络
- 学习的目标：找到f! 但怎样评估f对目标的拟合程度呢？ 限制条件是什么？

### 损失函数
- 假设函数 h(x)
- 损失函数   

  $$L(Y,\hat{Y})$$
- in-sample error, empirical risk:  

  $$R_{emp}(h)=\frac{1}{m}\sum_{i}^{m}L(y_{i},h(x_{i}))$$
- 问题解决了么？
### 泛化误差
   

  
      
      
    

